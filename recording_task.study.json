{
  "components": {
    "2": {
      "id": "2",
      "type": "lab.html.Page",
      "items": {
        "rows": [
          [
            {
              "required": true,
              "type": "html",
              "content": "<div class=\"wrapper\">\n  <link\n    href=\"https://mdn.github.io/web-dictaphone/styles/app.css\"\n    rel=\"stylesheet\"\n    type=\"text/css\"\n  />\n\n  <header>\n    <h1>Web dictaphone</h1>\n  </header>\n\n  <section class=\"main-controls\">\n    <canvas class=\"visualizer\" height=\"60px\"></canvas>\n    <div id=\"buttons\">\n      <button class=\"record\">Record</button>\n      <button class=\"stop\">Stop</button>\n    </div>\n  </section>\n\n  <section class=\"sound-clips\"></section>\n</div>\n\n<label for=\"toggle\">❔</label>\n<input type=\"checkbox\" id=\"toggle\" />\n\n<p>Information</p>\n\n<p>\n  Web dictaphone is built using\n  <a\n    href=\"https://developer.mozilla.org/en-US/docs/Web/API/Navigator.getUserMedia\"\n    >getUserMedia</a\n  >\n  and the\n  <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder_API\"\n    >MediaRecorder API</a\n  >, which provides an easier way to capture Media streams.\n</p>\n\n<p>\n  Icon courtesy of\n  <a href=\"http://findicons.com/search/microphone\">Find Icons</a>. Thanks to\n  <a href=\"http://soledadpenades.com/\">Sole</a> for the Oscilloscope code!\n</p>\n<!--\n  <script src=\"https://mdn.github.io/web-dictaphone/scripts/app.js\"></script>\n-->"
            }
          ]
        ]
      },
      "scrollTop": true,
      "submitButtonText": "Continue →",
      "submitButtonPosition": "right",
      "files": {
        "rows": []
      },
      "responses": {
        "rows": [
          [
            "",
            "",
            "",
            ""
          ]
        ]
      },
      "parameters": {
        "rows": [
          [
            {
              "name": "",
              "value": "",
              "type": "string"
            }
          ]
        ]
      },
      "messageHandlers": {
        "rows": [
          [
            {
              "title": "load dicta phone",
              "message": "run",
              "code": "// set up basic variables for app\n\nconst component = this;\nconst record = document.querySelector('.record');\nconst stop = document.querySelector('.stop');\nconst soundClips = document.querySelector('.sound-clips');\nconst canvas = document.querySelector('.visualizer');\nconst mainSection = document.querySelector('.main-controls');\n\n// disable stop button while not recording\n\nstop.disabled = true;\n\n// visualiser setup - create web audio api context and canvas\n\nlet audioCtx;\nconst canvasCtx = canvas.getContext(\"2d\");\n\n//main block for doing the audio recording\n\nif (navigator.mediaDevices.getUserMedia) {\n  console.log('getUserMedia supported.');\n\n  const constraints = { audio: true };\n  let chunks = [];\n\n  let onSuccess = function(stream) {\n    const mediaRecorder = new MediaRecorder(stream);\n\n    visualize(stream);\n\n    record.onclick = function(e) {\n      e.preventDefault()\n      mediaRecorder.start();\n      console.log(mediaRecorder.state);\n      console.log(\"recorder started\");\n      record.style.background = \"red\";\n\n      stop.disabled = false;\n      record.disabled = true;\n    }\n\n    stop.onclick = function(e) {\n      e.preventDefault()\n      mediaRecorder.stop();\n      console.log(mediaRecorder.state);\n      console.log(\"recorder stopped\");\n      record.style.background = \"\";\n      record.style.color = \"\";\n      // mediaRecorder.requestData();\n\n      stop.disabled = true;\n      record.disabled = false;\n    }\n\n    mediaRecorder.onstop = function(e) {\n      console.log(\"data available after MediaRecorder.stop() called.\");\n\n      const clipName = prompt('Enter a name for your sound clip?','My unnamed clip');\n\n      const clipContainer = document.createElement('article');\n      const clipLabel = document.createElement('p');\n      const audio = document.createElement('audio');\n      const deleteButton = document.createElement('button');\n\n      clipContainer.classList.add('clip');\n      audio.setAttribute('controls', '');\n      deleteButton.textContent = 'Delete';\n      deleteButton.className = 'delete';\n\n      if(clipName === null) {\n        clipLabel.textContent = 'My unnamed clip';\n      } else {\n        clipLabel.textContent = clipName;\n      }\n\n      clipContainer.appendChild(audio);\n      clipContainer.appendChild(clipLabel);\n      clipContainer.appendChild(deleteButton);\n      soundClips.appendChild(clipContainer);\n\n      audio.controls = true;\n      const blob = new Blob(chunks, { 'type' : 'audio/ogg; codecs=opus' });\n      chunks = [];\n      const audioURL = window.URL.createObjectURL(blob);\n      audio.src = audioURL;\n      console.log(\"recorder stopped\");\n\n      // Here we add to options.data to store off this data\n      var reader = new FileReader();\n      reader.readAsDataURL(blob); \n      reader.onloadend = function() {\n          var base64data = reader.result;                \n          //component.options.data['audio:newClipName'] = base64data;\n          component.options.datastore.set(\n            'audio:'+clipName, base64data\n          )\n          console.log('saved blob to data')\n      }\n\n      deleteButton.onclick = function(e) {\n        let evtTgt = e.target;\n        evtTgt.parentNode.parentNode.removeChild(evtTgt.parentNode);\n      }\n\n      clipLabel.onclick = function() {\n        const existingName = clipLabel.textContent;\n        const newClipName = prompt('Enter a new name for your sound clip?');\n        if(newClipName === null) {\n          clipLabel.textContent = existingName;\n        } else {\n          clipLabel.textContent = newClipName;\n        }\n      }\n    }\n\n    mediaRecorder.ondataavailable = function(e) {\n      chunks.push(e.data);\n    }\n  }\n\n  let onError = function(err) {\n    console.log('The following error occured: ' + err);\n  }\n\n  navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);\n\n} else {\n   console.log('getUserMedia not supported on your browser!');\n}\n\nfunction visualize(stream) {\n  if(!audioCtx) {\n    audioCtx = new AudioContext();\n  }\n\n  const source = audioCtx.createMediaStreamSource(stream);\n\n  const analyser = audioCtx.createAnalyser();\n  analyser.fftSize = 2048;\n  const bufferLength = analyser.frequencyBinCount;\n  const dataArray = new Uint8Array(bufferLength);\n\n  source.connect(analyser);\n  //analyser.connect(audioCtx.destination);\n\n  draw()\n\n  function draw() {\n    const WIDTH = canvas.width\n    const HEIGHT = canvas.height;\n\n    requestAnimationFrame(draw);\n\n    analyser.getByteTimeDomainData(dataArray);\n\n    canvasCtx.fillStyle = 'rgb(200, 200, 200)';\n    canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);\n\n    canvasCtx.lineWidth = 2;\n    canvasCtx.strokeStyle = 'rgb(0, 0, 0)';\n\n    canvasCtx.beginPath();\n\n    let sliceWidth = WIDTH * 1.0 / bufferLength;\n    let x = 0;\n\n\n    for(let i = 0; i < bufferLength; i++) {\n\n      let v = dataArray[i] / 128.0;\n      let y = v * HEIGHT/2;\n\n      if(i === 0) {\n        canvasCtx.moveTo(x, y);\n      } else {\n        canvasCtx.lineTo(x, y);\n      }\n\n      x += sliceWidth;\n    }\n\n    canvasCtx.lineTo(canvas.width, canvas.height/2);\n    canvasCtx.stroke();\n\n  }\n}\n\nwindow.onresize = function() {\n  canvas.width = mainSection.offsetWidth;\n}\n\nwindow.onresize();"
            }
          ]
        ]
      },
      "title": "Page",
      "_tab": "Scripts"
    },
    "root": {
      "id": "root",
      "title": "root",
      "type": "lab.flow.Sequence",
      "children": [
        "2"
      ],
      "parameters": {
        "rows": [
          [
            {
              "name": "",
              "value": "",
              "type": "string"
            }
          ]
        ]
      },
      "plugins": [
        {
          "type": "lab.plugins.Metadata"
        }
      ],
      "metadata": {
        "title": "Script for Lab.js recording task",
        "description": "This is a simple script with the bare minimium to record a subjects voice when the subject clicks record. The recording is stopped when the subject clicks stop.",
        "repository": "https://github.com/robinsonkwame/lab-js-recording-task",
        "contributors": "Kwame Porter Robinson (https://robinsonkwame.github.io/)"
      }
    }
  },
  "version": [
    20,
    0,
    1
  ],
  "files": {
    "files": {
      "index.html": {
        "content": "data:text/html,%3C!doctype%20html%3E%0A%3Chtml%3E%0A%3Chead%3E%0A%20%20%3Cmeta%20charset%3D%22utf-8%22%3E%0A%20%20%3Ctitle%3EExperiment%3C%2Ftitle%3E%0A%20%20%3C!--%20viewport%20setup%20--%3E%0A%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%20initial-scale%3D1%22%3E%0A%20%20%3C!--%20lab.js%20library%20and%20experiment%20code%20--%3E%0A%20%20%24%7B%20header%20%7D%0A%3C%2Fhead%3E%0A%3Cbody%3E%0A%20%20%3C!--%20If%20you'd%20rather%20have%20a%20container%20with%20a%20fixed%20width%0A%20%20%20%20%20%20%20and%20variable%20height%2C%20try%20removing%20the%20fullscreen%20class%20below%20--%3E%0A%20%20%3Cdiv%20class%3D%22container%20fullscreen%22%20data-labjs-section%3D%22main%22%3E%0A%20%20%20%20%3Cmain%20class%3D%22content-vertical-center%20content-horizontal-center%22%3E%0A%20%20%20%20%20%20%3Cdiv%3E%0A%20%20%20%20%20%20%20%20%3Ch2%3ELoading%20Experiment%3C%2Fh2%3E%0A%20%20%20%20%20%20%20%20%3Cp%3EThe%20experiment%20is%20loading%20and%20should%20start%20in%20a%20few%20seconds%3C%2Fp%3E%0A%20%20%20%20%20%20%3C%2Fdiv%3E%0A%20%20%20%20%3C%2Fmain%3E%0A%20%20%3C%2Fdiv%3E%0A%3C%2Fbody%3E%0A%3C%2Fhtml%3E%0A",
        "source": "library"
      },
      "style.css": {
        "content": "data:text/css,%2F*%20Please%20define%20your%20custom%20styles%20here%20*%2F",
        "source": "library"
      }
    },
    "bundledFiles": {
      "lib/lab.js": {
        "type": "application/javascript"
      },
      "lib/lab.js.map": {
        "type": "text/plain"
      },
      "lib/lab.fallback.js": {
        "type": "application/javascript"
      },
      "lib/lab.legacy.js": {
        "type": "application/javascript"
      },
      "lib/lab.legacy.js.map": {
        "type": "text/plain"
      },
      "lib/lab.css": {
        "type": "text/css"
      },
      "lib/loading.svg": {
        "type": "image/svg+xml"
      }
    }
  }
}